{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN 심화 (cifar10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "'''\n",
    "Torchvision : Python imaging format image를 불러옴\n",
    "transforms.Compose : 전처리 pipeline\n",
    "transforms.ToTensor : 이미지(range [0 , 255])를 float텐서(shape(CxHxW) with range[0.0, 1.0]) 형태로 뱐환\n",
    "PIL image (H x W x C) -> Tensor (C x H x W)\n",
    "transforms.Normalize : input = (input - 0.5 ) / 0.5\n",
    "'''\n",
    "\n",
    "# CIFAR10 data를 transform 시켜서 불러옴\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform)\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                       train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설정\n",
    "\n",
    "batch_size : 32\n",
    "\n",
    "epoch : 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "src = {'input_size':3*32*32,\n",
    "       'hidden_size1':50,\n",
    "       'hidden_size2':25,\n",
    "       'output_size':10,\n",
    "       'init_weight_range':0.5,\n",
    "       'num_epochs':10,\n",
    "       'batch_size':32,\n",
    "       'learning_rate':1e-3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "'''\n",
    "torch.utils.data.DataLoader : data를 batch size로 묶음\n",
    "'''\n",
    "\n",
    "trainloader = DataLoader(trainset, \n",
    "                         batch_size=src['batch_size'],\n",
    "                         shuffle=True, \n",
    "                         drop_last=False)\n",
    "\n",
    "testloader = DataLoader(testset, \n",
    "                        batch_size=src['batch_size'],\n",
    "                        shuffle=False,\n",
    "                        drop_last=False)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563\n",
      "torch.Size([32, 3, 32, 32])\n",
      "tensor([8, 8, 1, 6, 8, 0, 6, 3, 6, 1, 1, 3, 5, 7, 4, 8, 4, 2, 3, 1, 2, 1, 8, 7,\n",
      "        9, 8, 3, 9, 6, 7, 1, 7])\n"
     ]
    }
   ],
   "source": [
    "trainiter = iter(trainloader)\n",
    "images, labels = trainiter.next()\n",
    "\n",
    "print(len(trainloader))\n",
    "print(images.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 모델 \n",
    "\n",
    "linear - relu - linear - relu - linear - softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, src):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(src['input_size'], src['hidden_size1'])\n",
    "        self.fc2 = nn.Linear(src['hidden_size1'], src['hidden_size2'])\n",
    "        self.fc3 = nn.Linear(src['hidden_size2'], src['output_size'])\n",
    "                             \n",
    "        \n",
    "        self.init_range = src['init_weight_range']\n",
    "    \n",
    "    #가중치 초기화\n",
    "    def init_weight(self): \n",
    "        self.fc1.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.fc2.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.fc3.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        \n",
    "    def forward(self, img):\n",
    "        x = img.view(img.shape[0], -1)\n",
    "        #--------------------\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x) #relu\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x) #relu\n",
    "        \n",
    "        y = self.fc3(x)\n",
    "        #y = F.softmax(x, dim=0) #softmax\n",
    "        #--------------------\n",
    "        \n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropout 모델 \n",
    "\n",
    "linear - relu - dropout - linear - relu - dropout - linear - softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net_dropout(nn.Module):\n",
    "    def __init__(self, src):\n",
    "        super(Net_dropout, self).__init__()\n",
    "        self.fc1 = nn.Linear(src['input_size'], src['hidden_size1'])\n",
    "        self.fc2 = nn.Linear(src['hidden_size1'], src['hidden_size2'])\n",
    "        self.fc3 = nn.Linear(src['hidden_size2'], src['output_size'])\n",
    "        \n",
    "        self.init_range = src['init_weight_range']\n",
    "    \n",
    "    #가중치 초기화\n",
    "    def init_weight(self): \n",
    "        self.fc1.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.fc2.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.fc3.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        \n",
    "    def forward(self, img):\n",
    "        x = img.view(img.shape[0], -1)\n",
    "        #--------------------\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x) #relu\n",
    "        x = F.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x) #relu\n",
    "        x = F.dropout(x)\n",
    "        \n",
    "        y = self.fc3(x)\n",
    "        #y = F.softmax(x, dim=0) #softmax\n",
    "        #--------------------\n",
    "        \n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch normalization 모델 \n",
    "\n",
    "linear - relu - batchNorm - linear - relu - batchNorm - linear - softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net_batchnorm(nn.Module):\n",
    "    def __init__(self, src):\n",
    "        super(Net_batchnorm, self).__init__()\n",
    "        self.fc1 = nn.Linear(src['input_size'], src['hidden_size1'])\n",
    "        self.bn1 = nn.BatchNorm1d(src['hidden_size1'])\n",
    "        self.fc2 = nn.Linear(src['hidden_size1'], src['hidden_size2'])\n",
    "        self.bn2 = nn.BatchNorm1d(src['hidden_size2'])\n",
    "        self.fc3 = nn.Linear(src['hidden_size2'], src['output_size'])\n",
    "        \n",
    "        self.init_range = src['init_weight_range']\n",
    "    \n",
    "    #가중치 초기화\n",
    "    def init_weight(self): \n",
    "        self.fc1.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.fc2.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        self.fc3.weight.data.uniform_(-self.init_range, self.init_range)\n",
    "        \n",
    "    def forward(self, img):\n",
    "        x = img.view(img.shape[0], -1)\n",
    "        #--------------------\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x) #relu\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x) #relu\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        y = self.fc3(x)\n",
    "        #y = F.softmax(x, dim=0) #softmax\n",
    "        #--------------------\n",
    "        \n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기본 모델 monentum 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(src)\n",
    "y = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      src['learning_rate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/1500], Loss: 10.4984\n",
      "Epoch [1/10], Step [200/1500], Loss: 7.5930\n",
      "Epoch [1/10], Step [300/1500], Loss: 6.2303\n",
      "Epoch [1/10], Step [400/1500], Loss: 5.2828\n",
      "Epoch [1/10], Step [500/1500], Loss: 4.7198\n",
      "Epoch [1/10], Step [600/1500], Loss: 4.2201\n",
      "Epoch [1/10], Step [700/1500], Loss: 3.7854\n",
      "Epoch [1/10], Step [800/1500], Loss: 3.5847\n",
      "Epoch [1/10], Step [900/1500], Loss: 3.2589\n",
      "Epoch [1/10], Step [1000/1500], Loss: 3.1466\n",
      "Epoch [1/10], Step [1100/1500], Loss: 3.0973\n",
      "Epoch [1/10], Step [1200/1500], Loss: 2.8837\n",
      "Epoch [1/10], Step [1300/1500], Loss: 2.8317\n",
      "Epoch [1/10], Step [1400/1500], Loss: 2.7001\n",
      "Epoch [1/10], Step [1500/1500], Loss: 2.6719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 1/10 [00:20<03:03, 20.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [100/1500], Loss: 2.5885\n",
      "Epoch [2/10], Step [200/1500], Loss: 2.5065\n",
      "Epoch [2/10], Step [300/1500], Loss: 2.4446\n",
      "Epoch [2/10], Step [400/1500], Loss: 2.4405\n",
      "Epoch [2/10], Step [500/1500], Loss: 2.4457\n",
      "Epoch [2/10], Step [600/1500], Loss: 2.4105\n",
      "Epoch [2/10], Step [700/1500], Loss: 2.4144\n",
      "Epoch [2/10], Step [800/1500], Loss: 2.3657\n",
      "Epoch [2/10], Step [900/1500], Loss: 2.3259\n",
      "Epoch [2/10], Step [1000/1500], Loss: 2.3381\n",
      "Epoch [2/10], Step [1100/1500], Loss: 2.3307\n",
      "Epoch [2/10], Step [1200/1500], Loss: 2.3232\n",
      "Epoch [2/10], Step [1300/1500], Loss: 2.2708\n",
      "Epoch [2/10], Step [1400/1500], Loss: 2.2654\n",
      "Epoch [2/10], Step [1500/1500], Loss: 2.2798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 2/10 [00:40<02:42, 20.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [100/1500], Loss: 2.2583\n",
      "Epoch [3/10], Step [200/1500], Loss: 2.2142\n",
      "Epoch [3/10], Step [300/1500], Loss: 2.2349\n",
      "Epoch [3/10], Step [400/1500], Loss: 2.2443\n",
      "Epoch [3/10], Step [500/1500], Loss: 2.2221\n",
      "Epoch [3/10], Step [600/1500], Loss: 2.2217\n",
      "Epoch [3/10], Step [700/1500], Loss: 2.2181\n",
      "Epoch [3/10], Step [800/1500], Loss: 2.2134\n",
      "Epoch [3/10], Step [900/1500], Loss: 2.1979\n",
      "Epoch [3/10], Step [1000/1500], Loss: 2.2102\n",
      "Epoch [3/10], Step [1100/1500], Loss: 2.1920\n",
      "Epoch [3/10], Step [1200/1500], Loss: 2.1698\n",
      "Epoch [3/10], Step [1300/1500], Loss: 2.1948\n",
      "Epoch [3/10], Step [1400/1500], Loss: 2.1708\n",
      "Epoch [3/10], Step [1500/1500], Loss: 2.1801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 3/10 [01:00<02:21, 20.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [100/1500], Loss: 2.1613\n",
      "Epoch [4/10], Step [200/1500], Loss: 2.1613\n",
      "Epoch [4/10], Step [300/1500], Loss: 2.1609\n",
      "Epoch [4/10], Step [400/1500], Loss: 2.1468\n",
      "Epoch [4/10], Step [500/1500], Loss: 2.1671\n",
      "Epoch [4/10], Step [600/1500], Loss: 2.1372\n",
      "Epoch [4/10], Step [700/1500], Loss: 2.1490\n",
      "Epoch [4/10], Step [800/1500], Loss: 2.1586\n",
      "Epoch [4/10], Step [900/1500], Loss: 2.1377\n",
      "Epoch [4/10], Step [1000/1500], Loss: 2.1426\n",
      "Epoch [4/10], Step [1100/1500], Loss: 2.1163\n",
      "Epoch [4/10], Step [1200/1500], Loss: 2.1302\n",
      "Epoch [4/10], Step [1300/1500], Loss: 2.1537\n",
      "Epoch [4/10], Step [1400/1500], Loss: 2.1541\n",
      "Epoch [4/10], Step [1500/1500], Loss: 2.1409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [01:23<02:05, 20.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [100/1500], Loss: 2.1335\n",
      "Epoch [5/10], Step [200/1500], Loss: 2.1053\n",
      "Epoch [5/10], Step [300/1500], Loss: 2.1032\n",
      "Epoch [5/10], Step [400/1500], Loss: 2.1120\n",
      "Epoch [5/10], Step [500/1500], Loss: 2.1209\n",
      "Epoch [5/10], Step [600/1500], Loss: 2.0970\n",
      "Epoch [5/10], Step [700/1500], Loss: 2.1124\n",
      "Epoch [5/10], Step [800/1500], Loss: 2.0773\n",
      "Epoch [5/10], Step [900/1500], Loss: 2.1039\n",
      "Epoch [5/10], Step [1000/1500], Loss: 2.1002\n",
      "Epoch [5/10], Step [1100/1500], Loss: 2.0895\n",
      "Epoch [5/10], Step [1200/1500], Loss: 2.1190\n",
      "Epoch [5/10], Step [1300/1500], Loss: 2.1041\n",
      "Epoch [5/10], Step [1400/1500], Loss: 2.1080\n",
      "Epoch [5/10], Step [1500/1500], Loss: 2.0918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [01:43<01:44, 20.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [100/1500], Loss: 2.0760\n",
      "Epoch [6/10], Step [200/1500], Loss: 2.1019\n",
      "Epoch [6/10], Step [300/1500], Loss: 2.0922\n",
      "Epoch [6/10], Step [400/1500], Loss: 2.0624\n",
      "Epoch [6/10], Step [500/1500], Loss: 2.0678\n",
      "Epoch [6/10], Step [600/1500], Loss: 2.0700\n",
      "Epoch [6/10], Step [700/1500], Loss: 2.0763\n",
      "Epoch [6/10], Step [800/1500], Loss: 2.0947\n",
      "Epoch [6/10], Step [900/1500], Loss: 2.0758\n",
      "Epoch [6/10], Step [1000/1500], Loss: 2.0749\n",
      "Epoch [6/10], Step [1100/1500], Loss: 2.0815\n",
      "Epoch [6/10], Step [1200/1500], Loss: 2.0707\n",
      "Epoch [6/10], Step [1300/1500], Loss: 2.0523\n",
      "Epoch [6/10], Step [1400/1500], Loss: 2.0505\n",
      "Epoch [6/10], Step [1500/1500], Loss: 2.0727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [02:03<01:22, 20.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [100/1500], Loss: 2.0692\n",
      "Epoch [7/10], Step [200/1500], Loss: 2.0805\n",
      "Epoch [7/10], Step [300/1500], Loss: 2.0632\n",
      "Epoch [7/10], Step [400/1500], Loss: 2.0412\n",
      "Epoch [7/10], Step [500/1500], Loss: 2.0413\n",
      "Epoch [7/10], Step [600/1500], Loss: 2.0686\n",
      "Epoch [7/10], Step [700/1500], Loss: 2.0411\n",
      "Epoch [7/10], Step [800/1500], Loss: 2.0417\n",
      "Epoch [7/10], Step [900/1500], Loss: 2.0626\n",
      "Epoch [7/10], Step [1000/1500], Loss: 2.0924\n",
      "Epoch [7/10], Step [1100/1500], Loss: 2.0605\n",
      "Epoch [7/10], Step [1200/1500], Loss: 2.0224\n",
      "Epoch [7/10], Step [1300/1500], Loss: 2.0545\n",
      "Epoch [7/10], Step [1400/1500], Loss: 2.0144\n",
      "Epoch [7/10], Step [1500/1500], Loss: 2.0391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [02:23<01:01, 20.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [100/1500], Loss: 2.0324\n",
      "Epoch [8/10], Step [200/1500], Loss: 2.0147\n",
      "Epoch [8/10], Step [300/1500], Loss: 2.0545\n",
      "Epoch [8/10], Step [400/1500], Loss: 2.0374\n",
      "Epoch [8/10], Step [500/1500], Loss: 2.0430\n",
      "Epoch [8/10], Step [600/1500], Loss: 2.0323\n",
      "Epoch [8/10], Step [700/1500], Loss: 2.0467\n",
      "Epoch [8/10], Step [800/1500], Loss: 2.0456\n",
      "Epoch [8/10], Step [900/1500], Loss: 2.0303\n",
      "Epoch [8/10], Step [1000/1500], Loss: 2.0302\n",
      "Epoch [8/10], Step [1100/1500], Loss: 2.0252\n",
      "Epoch [8/10], Step [1200/1500], Loss: 2.0463\n",
      "Epoch [8/10], Step [1300/1500], Loss: 2.0209\n",
      "Epoch [8/10], Step [1400/1500], Loss: 2.0352\n",
      "Epoch [8/10], Step [1500/1500], Loss: 2.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [02:44<00:41, 20.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [100/1500], Loss: 2.0762\n",
      "Epoch [9/10], Step [200/1500], Loss: 2.0236\n",
      "Epoch [9/10], Step [300/1500], Loss: 2.0169\n",
      "Epoch [9/10], Step [400/1500], Loss: 2.0154\n",
      "Epoch [9/10], Step [500/1500], Loss: 2.0327\n",
      "Epoch [9/10], Step [600/1500], Loss: 2.0326\n",
      "Epoch [9/10], Step [700/1500], Loss: 2.0247\n",
      "Epoch [9/10], Step [800/1500], Loss: 2.0138\n",
      "Epoch [9/10], Step [900/1500], Loss: 1.9843\n",
      "Epoch [9/10], Step [1000/1500], Loss: 2.0436\n",
      "Epoch [9/10], Step [1100/1500], Loss: 2.0105\n",
      "Epoch [9/10], Step [1200/1500], Loss: 1.9946\n",
      "Epoch [9/10], Step [1300/1500], Loss: 2.0269\n",
      "Epoch [9/10], Step [1400/1500], Loss: 2.0091\n",
      "Epoch [9/10], Step [1500/1500], Loss: 1.9892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [03:04<00:20, 20.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [100/1500], Loss: 1.9908\n",
      "Epoch [10/10], Step [200/1500], Loss: 2.0072\n",
      "Epoch [10/10], Step [300/1500], Loss: 2.0216\n",
      "Epoch [10/10], Step [400/1500], Loss: 2.0254\n",
      "Epoch [10/10], Step [500/1500], Loss: 1.9955\n",
      "Epoch [10/10], Step [600/1500], Loss: 2.0185\n",
      "Epoch [10/10], Step [700/1500], Loss: 2.0126\n",
      "Epoch [10/10], Step [800/1500], Loss: 1.9880\n",
      "Epoch [10/10], Step [900/1500], Loss: 2.0088\n",
      "Epoch [10/10], Step [1000/1500], Loss: 2.0130\n",
      "Epoch [10/10], Step [1100/1500], Loss: 2.0232\n",
      "Epoch [10/10], Step [1200/1500], Loss: 1.9869\n",
      "Epoch [10/10], Step [1300/1500], Loss: 1.9879\n",
      "Epoch [10/10], Step [1400/1500], Loss: 2.0088\n",
      "Epoch [10/10], Step [1500/1500], Loss: 1.9926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:25<00:00, 20.52s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "time_start = time.time()\n",
    "\n",
    "model.init_weight()\n",
    "\n",
    "for epoch in tqdm(range(src['num_epochs'])):\n",
    "    current_loss = 0.0\n",
    "#     model.train(True)\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        step = i + 1\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        if step % 100 == 0 and step != 0:     # print every 100 mini-batches\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' %\n",
    "                  (epoch + 1, src['num_epochs'], step, len(trainloader)//100 * 100, current_loss / 100))\n",
    "            current_loss = 0.0 #100번동안 있었던 loss의 누적값 평균, 그 후 reset\n",
    "\n",
    "traintime = time.time() - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2500 test images: 26 %\n",
      "Time elapsed: 205.56801676750183 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for i, data in enumerate(testloader):\n",
    "    inputs, labels = data\n",
    "#     images = images.view(-1, 28*28)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.shape[0]\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "print( 'Time elapsed: {} seconds'.format(traintime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기본 모델 Adam 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(src)\n",
    "y = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                      src['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/1500], Loss: 6.4845\n",
      "Epoch [1/10], Step [200/1500], Loss: 3.0964\n",
      "Epoch [1/10], Step [300/1500], Loss: 2.5269\n",
      "Epoch [1/10], Step [400/1500], Loss: 2.2942\n",
      "Epoch [1/10], Step [500/1500], Loss: 2.2676\n",
      "Epoch [1/10], Step [600/1500], Loss: 2.1942\n",
      "Epoch [1/10], Step [700/1500], Loss: 2.1171\n",
      "Epoch [1/10], Step [800/1500], Loss: 2.1078\n",
      "Epoch [1/10], Step [900/1500], Loss: 2.0683\n",
      "Epoch [1/10], Step [1000/1500], Loss: 2.0579\n",
      "Epoch [1/10], Step [1100/1500], Loss: 2.0098\n",
      "Epoch [1/10], Step [1200/1500], Loss: 2.0435\n",
      "Epoch [1/10], Step [1300/1500], Loss: 2.0180\n",
      "Epoch [1/10], Step [1400/1500], Loss: 1.9875\n",
      "Epoch [1/10], Step [1500/1500], Loss: 1.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 1/10 [00:22<03:23, 22.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [100/1500], Loss: 1.9272\n",
      "Epoch [2/10], Step [200/1500], Loss: 1.8924\n",
      "Epoch [2/10], Step [300/1500], Loss: 1.9015\n",
      "Epoch [2/10], Step [400/1500], Loss: 1.9004\n",
      "Epoch [2/10], Step [500/1500], Loss: 1.8835\n",
      "Epoch [2/10], Step [600/1500], Loss: 1.9017\n",
      "Epoch [2/10], Step [700/1500], Loss: 1.8668\n",
      "Epoch [2/10], Step [800/1500], Loss: 1.8895\n",
      "Epoch [2/10], Step [900/1500], Loss: 1.8461\n",
      "Epoch [2/10], Step [1000/1500], Loss: 1.8490\n",
      "Epoch [2/10], Step [1100/1500], Loss: 1.8294\n",
      "Epoch [2/10], Step [1200/1500], Loss: 1.8723\n",
      "Epoch [2/10], Step [1300/1500], Loss: 1.8527\n",
      "Epoch [2/10], Step [1400/1500], Loss: 1.8275\n",
      "Epoch [2/10], Step [1500/1500], Loss: 1.8148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 2/10 [00:45<03:01, 22.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [100/1500], Loss: 1.7913\n",
      "Epoch [3/10], Step [200/1500], Loss: 1.7540\n",
      "Epoch [3/10], Step [300/1500], Loss: 1.7611\n",
      "Epoch [3/10], Step [400/1500], Loss: 1.7656\n",
      "Epoch [3/10], Step [500/1500], Loss: 1.7528\n",
      "Epoch [3/10], Step [600/1500], Loss: 1.7723\n",
      "Epoch [3/10], Step [700/1500], Loss: 1.7685\n",
      "Epoch [3/10], Step [800/1500], Loss: 1.7331\n",
      "Epoch [3/10], Step [900/1500], Loss: 1.7412\n",
      "Epoch [3/10], Step [1000/1500], Loss: 1.7134\n",
      "Epoch [3/10], Step [1100/1500], Loss: 1.7339\n",
      "Epoch [3/10], Step [1200/1500], Loss: 1.7265\n",
      "Epoch [3/10], Step [1300/1500], Loss: 1.7056\n",
      "Epoch [3/10], Step [1400/1500], Loss: 1.7406\n",
      "Epoch [3/10], Step [1500/1500], Loss: 1.7231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 3/10 [01:07<02:37, 22.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [100/1500], Loss: 1.6781\n",
      "Epoch [4/10], Step [200/1500], Loss: 1.6618\n",
      "Epoch [4/10], Step [300/1500], Loss: 1.6460\n",
      "Epoch [4/10], Step [400/1500], Loss: 1.6734\n",
      "Epoch [4/10], Step [500/1500], Loss: 1.6615\n",
      "Epoch [4/10], Step [600/1500], Loss: 1.6784\n",
      "Epoch [4/10], Step [700/1500], Loss: 1.6782\n",
      "Epoch [4/10], Step [800/1500], Loss: 1.6474\n",
      "Epoch [4/10], Step [900/1500], Loss: 1.6291\n",
      "Epoch [4/10], Step [1000/1500], Loss: 1.6618\n",
      "Epoch [4/10], Step [1100/1500], Loss: 1.6522\n",
      "Epoch [4/10], Step [1200/1500], Loss: 1.6191\n",
      "Epoch [4/10], Step [1300/1500], Loss: 1.6438\n",
      "Epoch [4/10], Step [1400/1500], Loss: 1.6516\n",
      "Epoch [4/10], Step [1500/1500], Loss: 1.6493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [01:29<02:14, 22.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [100/1500], Loss: 1.5883\n",
      "Epoch [5/10], Step [200/1500], Loss: 1.6017\n",
      "Epoch [5/10], Step [300/1500], Loss: 1.5577\n",
      "Epoch [5/10], Step [400/1500], Loss: 1.6246\n",
      "Epoch [5/10], Step [500/1500], Loss: 1.5870\n",
      "Epoch [5/10], Step [600/1500], Loss: 1.6131\n",
      "Epoch [5/10], Step [700/1500], Loss: 1.5786\n",
      "Epoch [5/10], Step [800/1500], Loss: 1.6048\n",
      "Epoch [5/10], Step [900/1500], Loss: 1.5764\n",
      "Epoch [5/10], Step [1000/1500], Loss: 1.5740\n",
      "Epoch [5/10], Step [1100/1500], Loss: 1.5523\n",
      "Epoch [5/10], Step [1200/1500], Loss: 1.5535\n",
      "Epoch [5/10], Step [1300/1500], Loss: 1.5917\n",
      "Epoch [5/10], Step [1400/1500], Loss: 1.5738\n",
      "Epoch [5/10], Step [1500/1500], Loss: 1.5551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [01:56<01:58, 23.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [100/1500], Loss: 1.5376\n",
      "Epoch [6/10], Step [200/1500], Loss: 1.5235\n",
      "Epoch [6/10], Step [300/1500], Loss: 1.5116\n",
      "Epoch [6/10], Step [400/1500], Loss: 1.5178\n",
      "Epoch [6/10], Step [500/1500], Loss: 1.5130\n",
      "Epoch [6/10], Step [600/1500], Loss: 1.5272\n",
      "Epoch [6/10], Step [700/1500], Loss: 1.5397\n",
      "Epoch [6/10], Step [800/1500], Loss: 1.4981\n",
      "Epoch [6/10], Step [900/1500], Loss: 1.5456\n",
      "Epoch [6/10], Step [1000/1500], Loss: 1.5543\n",
      "Epoch [6/10], Step [1100/1500], Loss: 1.4888\n",
      "Epoch [6/10], Step [1200/1500], Loss: 1.5101\n",
      "Epoch [6/10], Step [1300/1500], Loss: 1.5380\n",
      "Epoch [6/10], Step [1400/1500], Loss: 1.5382\n",
      "Epoch [6/10], Step [1500/1500], Loss: 1.5207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [02:18<01:33, 23.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [100/1500], Loss: 1.4790\n",
      "Epoch [7/10], Step [200/1500], Loss: 1.4658\n",
      "Epoch [7/10], Step [300/1500], Loss: 1.4874\n",
      "Epoch [7/10], Step [400/1500], Loss: 1.4741\n",
      "Epoch [7/10], Step [500/1500], Loss: 1.4870\n",
      "Epoch [7/10], Step [600/1500], Loss: 1.4619\n",
      "Epoch [7/10], Step [700/1500], Loss: 1.4845\n",
      "Epoch [7/10], Step [800/1500], Loss: 1.4770\n",
      "Epoch [7/10], Step [900/1500], Loss: 1.4625\n",
      "Epoch [7/10], Step [1000/1500], Loss: 1.4653\n",
      "Epoch [7/10], Step [1100/1500], Loss: 1.4766\n",
      "Epoch [7/10], Step [1200/1500], Loss: 1.4512\n",
      "Epoch [7/10], Step [1300/1500], Loss: 1.4752\n",
      "Epoch [7/10], Step [1400/1500], Loss: 1.4698\n",
      "Epoch [7/10], Step [1500/1500], Loss: 1.5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [02:43<01:11, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [100/1500], Loss: 1.4324\n",
      "Epoch [8/10], Step [200/1500], Loss: 1.4313\n",
      "Epoch [8/10], Step [300/1500], Loss: 1.4515\n",
      "Epoch [8/10], Step [400/1500], Loss: 1.3988\n",
      "Epoch [8/10], Step [500/1500], Loss: 1.4546\n",
      "Epoch [8/10], Step [600/1500], Loss: 1.4252\n",
      "Epoch [8/10], Step [700/1500], Loss: 1.4516\n",
      "Epoch [8/10], Step [800/1500], Loss: 1.4475\n",
      "Epoch [8/10], Step [900/1500], Loss: 1.4416\n",
      "Epoch [8/10], Step [1000/1500], Loss: 1.4219\n",
      "Epoch [8/10], Step [1100/1500], Loss: 1.4559\n",
      "Epoch [8/10], Step [1200/1500], Loss: 1.4339\n",
      "Epoch [8/10], Step [1300/1500], Loss: 1.4536\n",
      "Epoch [8/10], Step [1400/1500], Loss: 1.4495\n",
      "Epoch [8/10], Step [1500/1500], Loss: 1.4645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [03:07<00:47, 23.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [100/1500], Loss: 1.4124\n",
      "Epoch [9/10], Step [200/1500], Loss: 1.4135\n",
      "Epoch [9/10], Step [300/1500], Loss: 1.3940\n",
      "Epoch [9/10], Step [400/1500], Loss: 1.3841\n",
      "Epoch [9/10], Step [500/1500], Loss: 1.4199\n",
      "Epoch [9/10], Step [600/1500], Loss: 1.4076\n",
      "Epoch [9/10], Step [700/1500], Loss: 1.4140\n",
      "Epoch [9/10], Step [800/1500], Loss: 1.4185\n",
      "Epoch [9/10], Step [900/1500], Loss: 1.3975\n",
      "Epoch [9/10], Step [1000/1500], Loss: 1.4518\n",
      "Epoch [9/10], Step [1100/1500], Loss: 1.4107\n",
      "Epoch [9/10], Step [1200/1500], Loss: 1.4086\n",
      "Epoch [9/10], Step [1300/1500], Loss: 1.4156\n",
      "Epoch [9/10], Step [1400/1500], Loss: 1.4246\n",
      "Epoch [9/10], Step [1500/1500], Loss: 1.4181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [03:33<00:24, 24.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [100/1500], Loss: 1.3611\n",
      "Epoch [10/10], Step [200/1500], Loss: 1.3670\n",
      "Epoch [10/10], Step [300/1500], Loss: 1.3867\n",
      "Epoch [10/10], Step [400/1500], Loss: 1.3961\n",
      "Epoch [10/10], Step [500/1500], Loss: 1.3838\n",
      "Epoch [10/10], Step [600/1500], Loss: 1.4258\n",
      "Epoch [10/10], Step [700/1500], Loss: 1.3830\n",
      "Epoch [10/10], Step [800/1500], Loss: 1.3726\n",
      "Epoch [10/10], Step [900/1500], Loss: 1.3862\n",
      "Epoch [10/10], Step [1000/1500], Loss: 1.3470\n",
      "Epoch [10/10], Step [1100/1500], Loss: 1.3578\n",
      "Epoch [10/10], Step [1200/1500], Loss: 1.3670\n",
      "Epoch [10/10], Step [1300/1500], Loss: 1.3627\n",
      "Epoch [10/10], Step [1400/1500], Loss: 1.4179\n",
      "Epoch [10/10], Step [1500/1500], Loss: 1.3857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:55<00:00, 23.81s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "time_start = time.time()\n",
    "\n",
    "model.init_weight()\n",
    "\n",
    "for epoch in tqdm(range(src['num_epochs'])):\n",
    "    current_loss = 0.0\n",
    "#     model.train(True)\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        step = i + 1\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        if step % 100 == 0 and step != 0:     # print every 100 mini-batches\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' %\n",
    "                  (epoch + 1, src['num_epochs'], step, len(trainloader)//100 * 100, current_loss / 100))\n",
    "            current_loss = 0.0 #100번동안 있었던 loss의 누적값 평균, 그 후 reset\n",
    "            \n",
    "traintime = time.time() - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2500 test images: 46 %\n",
      "Time elapsed: 235.60971903800964 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for i, data in enumerate(testloader):\n",
    "    inputs, labels = data\n",
    "#     images = images.view(-1, 28*28)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.shape[0]\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "print( 'Time elapsed: {} seconds'.format(traintime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dropout 모델  Adam 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Net_dropout(src)\n",
    "y = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                      src['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/1500], Loss: 18.4021\n",
      "Epoch [1/10], Step [200/1500], Loss: 8.9140\n",
      "Epoch [1/10], Step [300/1500], Loss: 5.9350\n",
      "Epoch [1/10], Step [400/1500], Loss: 4.4418\n",
      "Epoch [1/10], Step [500/1500], Loss: 3.5873\n",
      "Epoch [1/10], Step [600/1500], Loss: 3.2491\n",
      "Epoch [1/10], Step [700/1500], Loss: 2.8618\n",
      "Epoch [1/10], Step [800/1500], Loss: 2.7565\n",
      "Epoch [1/10], Step [900/1500], Loss: 2.7134\n",
      "Epoch [1/10], Step [1000/1500], Loss: 2.5732\n",
      "Epoch [1/10], Step [1100/1500], Loss: 2.5002\n",
      "Epoch [1/10], Step [1200/1500], Loss: 2.4614\n",
      "Epoch [1/10], Step [1300/1500], Loss: 2.4137\n",
      "Epoch [1/10], Step [1400/1500], Loss: 2.4171\n",
      "Epoch [1/10], Step [1500/1500], Loss: 2.3814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 1/10 [00:25<03:46, 25.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [100/1500], Loss: 2.3742\n",
      "Epoch [2/10], Step [200/1500], Loss: 2.3670\n",
      "Epoch [2/10], Step [300/1500], Loss: 2.3759\n",
      "Epoch [2/10], Step [400/1500], Loss: 2.3521\n",
      "Epoch [2/10], Step [500/1500], Loss: 2.3420\n",
      "Epoch [2/10], Step [600/1500], Loss: 2.3255\n",
      "Epoch [2/10], Step [700/1500], Loss: 2.3302\n",
      "Epoch [2/10], Step [800/1500], Loss: 2.2994\n",
      "Epoch [2/10], Step [900/1500], Loss: 2.3168\n",
      "Epoch [2/10], Step [1000/1500], Loss: 2.3150\n",
      "Epoch [2/10], Step [1100/1500], Loss: 2.3000\n",
      "Epoch [2/10], Step [1200/1500], Loss: 2.2994\n",
      "Epoch [2/10], Step [1300/1500], Loss: 2.2994\n",
      "Epoch [2/10], Step [1400/1500], Loss: 2.2878\n",
      "Epoch [2/10], Step [1500/1500], Loss: 2.2622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 2/10 [00:49<03:19, 24.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [100/1500], Loss: 2.2570\n",
      "Epoch [3/10], Step [200/1500], Loss: 2.2597\n",
      "Epoch [3/10], Step [300/1500], Loss: 2.2621\n",
      "Epoch [3/10], Step [400/1500], Loss: 2.2363\n",
      "Epoch [3/10], Step [500/1500], Loss: 2.2472\n",
      "Epoch [3/10], Step [600/1500], Loss: 2.2378\n",
      "Epoch [3/10], Step [700/1500], Loss: 2.2268\n",
      "Epoch [3/10], Step [800/1500], Loss: 2.2201\n",
      "Epoch [3/10], Step [900/1500], Loss: 2.2059\n",
      "Epoch [3/10], Step [1000/1500], Loss: 2.1968\n",
      "Epoch [3/10], Step [1100/1500], Loss: 2.1925\n",
      "Epoch [3/10], Step [1200/1500], Loss: 2.2036\n",
      "Epoch [3/10], Step [1300/1500], Loss: 2.1701\n",
      "Epoch [3/10], Step [1400/1500], Loss: 2.1945\n",
      "Epoch [3/10], Step [1500/1500], Loss: 2.1673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 3/10 [01:12<02:50, 24.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [100/1500], Loss: 2.1691\n",
      "Epoch [4/10], Step [200/1500], Loss: 2.1948\n",
      "Epoch [4/10], Step [300/1500], Loss: 2.1712\n",
      "Epoch [4/10], Step [400/1500], Loss: 2.1738\n",
      "Epoch [4/10], Step [500/1500], Loss: 2.1628\n",
      "Epoch [4/10], Step [600/1500], Loss: 2.1611\n",
      "Epoch [4/10], Step [700/1500], Loss: 2.1618\n",
      "Epoch [4/10], Step [800/1500], Loss: 2.1462\n",
      "Epoch [4/10], Step [900/1500], Loss: 2.1658\n",
      "Epoch [4/10], Step [1000/1500], Loss: 2.1379\n",
      "Epoch [4/10], Step [1100/1500], Loss: 2.1487\n",
      "Epoch [4/10], Step [1200/1500], Loss: 2.1342\n",
      "Epoch [4/10], Step [1300/1500], Loss: 2.1236\n",
      "Epoch [4/10], Step [1400/1500], Loss: 2.1211\n",
      "Epoch [4/10], Step [1500/1500], Loss: 2.1176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [01:35<02:22, 23.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [100/1500], Loss: 2.1224\n",
      "Epoch [5/10], Step [200/1500], Loss: 2.1016\n",
      "Epoch [5/10], Step [300/1500], Loss: 2.1143\n",
      "Epoch [5/10], Step [400/1500], Loss: 2.1018\n",
      "Epoch [5/10], Step [500/1500], Loss: 2.0946\n",
      "Epoch [5/10], Step [600/1500], Loss: 2.0914\n",
      "Epoch [5/10], Step [700/1500], Loss: 2.1043\n",
      "Epoch [5/10], Step [800/1500], Loss: 2.1198\n",
      "Epoch [5/10], Step [900/1500], Loss: 2.0870\n",
      "Epoch [5/10], Step [1000/1500], Loss: 2.0636\n",
      "Epoch [5/10], Step [1100/1500], Loss: 2.0940\n",
      "Epoch [5/10], Step [1200/1500], Loss: 2.0910\n",
      "Epoch [5/10], Step [1300/1500], Loss: 2.0757\n",
      "Epoch [5/10], Step [1400/1500], Loss: 2.0804\n",
      "Epoch [5/10], Step [1500/1500], Loss: 2.0646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [01:57<01:56, 23.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [100/1500], Loss: 2.0555\n",
      "Epoch [6/10], Step [200/1500], Loss: 2.0705\n",
      "Epoch [6/10], Step [300/1500], Loss: 2.0478\n",
      "Epoch [6/10], Step [400/1500], Loss: 2.0426\n",
      "Epoch [6/10], Step [500/1500], Loss: 2.0636\n",
      "Epoch [6/10], Step [600/1500], Loss: 2.0723\n",
      "Epoch [6/10], Step [700/1500], Loss: 2.0728\n",
      "Epoch [6/10], Step [800/1500], Loss: 2.0519\n",
      "Epoch [6/10], Step [900/1500], Loss: 2.0607\n",
      "Epoch [6/10], Step [1000/1500], Loss: 2.0180\n",
      "Epoch [6/10], Step [1100/1500], Loss: 2.0298\n",
      "Epoch [6/10], Step [1200/1500], Loss: 2.0183\n",
      "Epoch [6/10], Step [1300/1500], Loss: 2.0201\n",
      "Epoch [6/10], Step [1400/1500], Loss: 2.0321\n",
      "Epoch [6/10], Step [1500/1500], Loss: 2.0528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [02:19<01:32, 23.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [100/1500], Loss: 2.0333\n",
      "Epoch [7/10], Step [200/1500], Loss: 2.0353\n",
      "Epoch [7/10], Step [300/1500], Loss: 2.0172\n",
      "Epoch [7/10], Step [400/1500], Loss: 2.0389\n",
      "Epoch [7/10], Step [500/1500], Loss: 2.0030\n",
      "Epoch [7/10], Step [600/1500], Loss: 2.0299\n",
      "Epoch [7/10], Step [700/1500], Loss: 2.0150\n",
      "Epoch [7/10], Step [800/1500], Loss: 2.0082\n",
      "Epoch [7/10], Step [900/1500], Loss: 1.9918\n",
      "Epoch [7/10], Step [1000/1500], Loss: 1.9973\n",
      "Epoch [7/10], Step [1100/1500], Loss: 2.0083\n",
      "Epoch [7/10], Step [1200/1500], Loss: 2.0090\n",
      "Epoch [7/10], Step [1300/1500], Loss: 2.0230\n",
      "Epoch [7/10], Step [1400/1500], Loss: 2.0132\n",
      "Epoch [7/10], Step [1500/1500], Loss: 2.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [02:41<01:08, 22.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [100/1500], Loss: 2.0061\n",
      "Epoch [8/10], Step [200/1500], Loss: 2.0323\n",
      "Epoch [8/10], Step [300/1500], Loss: 1.9615\n",
      "Epoch [8/10], Step [400/1500], Loss: 2.0161\n",
      "Epoch [8/10], Step [500/1500], Loss: 1.9754\n",
      "Epoch [8/10], Step [600/1500], Loss: 2.0110\n",
      "Epoch [8/10], Step [700/1500], Loss: 2.0056\n",
      "Epoch [8/10], Step [800/1500], Loss: 2.0076\n",
      "Epoch [8/10], Step [900/1500], Loss: 2.0079\n",
      "Epoch [8/10], Step [1000/1500], Loss: 2.0086\n",
      "Epoch [8/10], Step [1100/1500], Loss: 2.0087\n",
      "Epoch [8/10], Step [1200/1500], Loss: 1.9950\n",
      "Epoch [8/10], Step [1300/1500], Loss: 1.9931\n",
      "Epoch [8/10], Step [1400/1500], Loss: 1.9994\n",
      "Epoch [8/10], Step [1500/1500], Loss: 1.9634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [03:03<00:45, 22.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [100/1500], Loss: 1.9840\n",
      "Epoch [9/10], Step [200/1500], Loss: 1.9539\n",
      "Epoch [9/10], Step [300/1500], Loss: 1.9688\n",
      "Epoch [9/10], Step [400/1500], Loss: 1.9931\n",
      "Epoch [9/10], Step [500/1500], Loss: 1.9726\n",
      "Epoch [9/10], Step [600/1500], Loss: 1.9753\n",
      "Epoch [9/10], Step [700/1500], Loss: 1.9728\n",
      "Epoch [9/10], Step [800/1500], Loss: 1.9620\n",
      "Epoch [9/10], Step [900/1500], Loss: 1.9503\n",
      "Epoch [9/10], Step [1000/1500], Loss: 1.9596\n",
      "Epoch [9/10], Step [1100/1500], Loss: 1.9780\n",
      "Epoch [9/10], Step [1200/1500], Loss: 1.9609\n",
      "Epoch [9/10], Step [1300/1500], Loss: 1.9328\n",
      "Epoch [9/10], Step [1400/1500], Loss: 1.9497\n",
      "Epoch [9/10], Step [1500/1500], Loss: 1.9676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [03:27<00:22, 22.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [100/1500], Loss: 1.9665\n",
      "Epoch [10/10], Step [200/1500], Loss: 1.9539\n",
      "Epoch [10/10], Step [300/1500], Loss: 1.9521\n",
      "Epoch [10/10], Step [400/1500], Loss: 1.9550\n",
      "Epoch [10/10], Step [500/1500], Loss: 1.9622\n",
      "Epoch [10/10], Step [600/1500], Loss: 1.9531\n",
      "Epoch [10/10], Step [700/1500], Loss: 1.9271\n",
      "Epoch [10/10], Step [800/1500], Loss: 1.9623\n",
      "Epoch [10/10], Step [900/1500], Loss: 1.9316\n",
      "Epoch [10/10], Step [1000/1500], Loss: 1.9486\n",
      "Epoch [10/10], Step [1100/1500], Loss: 1.9598\n",
      "Epoch [10/10], Step [1200/1500], Loss: 1.9351\n",
      "Epoch [10/10], Step [1300/1500], Loss: 1.9409\n",
      "Epoch [10/10], Step [1400/1500], Loss: 1.9382\n",
      "Epoch [10/10], Step [1500/1500], Loss: 1.9687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:50<00:00, 22.95s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "time_start = time.time()\n",
    "\n",
    "model.init_weight()\n",
    "\n",
    "for epoch in tqdm(range(src['num_epochs'])):\n",
    "    current_loss = 0.0\n",
    "#     model.train(True)\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        step = i + 1\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        if step % 100 == 0 and step != 0:     # print every 100 mini-batches\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' %\n",
    "                  (epoch + 1, src['num_epochs'], step, len(trainloader)//100 * 100, current_loss / 100))\n",
    "            current_loss = 0.0 #100번동안 있었던 loss의 누적값 평균, 그 후 reset\n",
    "            \n",
    "traintime = time.time() - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2500 test images: 28 %\n",
      "Time elapsed: 230.63831567764282 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for i, data in enumerate(testloader):\n",
    "    inputs, labels = data\n",
    "#     images = images.view(-1, 28*28)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.shape[0]\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "print( 'Time elapsed: {} seconds'.format(traintime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### batchNormalization 모델  Adam 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Net_batchnorm(src)\n",
    "y = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                      src['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/1500], Loss: 2.2496\n",
      "Epoch [1/10], Step [200/1500], Loss: 2.0503\n",
      "Epoch [1/10], Step [300/1500], Loss: 1.9570\n",
      "Epoch [1/10], Step [400/1500], Loss: 1.9105\n",
      "Epoch [1/10], Step [500/1500], Loss: 1.8835\n",
      "Epoch [1/10], Step [600/1500], Loss: 1.7882\n",
      "Epoch [1/10], Step [700/1500], Loss: 1.7968\n",
      "Epoch [1/10], Step [800/1500], Loss: 1.7536\n",
      "Epoch [1/10], Step [900/1500], Loss: 1.7658\n",
      "Epoch [1/10], Step [1000/1500], Loss: 1.7425\n",
      "Epoch [1/10], Step [1100/1500], Loss: 1.7118\n",
      "Epoch [1/10], Step [1200/1500], Loss: 1.7244\n",
      "Epoch [1/10], Step [1300/1500], Loss: 1.6889\n",
      "Epoch [1/10], Step [1400/1500], Loss: 1.6791\n",
      "Epoch [1/10], Step [1500/1500], Loss: 1.7029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 1/10 [00:31<04:46, 31.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [100/1500], Loss: 1.6239\n",
      "Epoch [2/10], Step [200/1500], Loss: 1.6515\n",
      "Epoch [2/10], Step [300/1500], Loss: 1.6475\n",
      "Epoch [2/10], Step [400/1500], Loss: 1.6082\n",
      "Epoch [2/10], Step [500/1500], Loss: 1.6377\n",
      "Epoch [2/10], Step [600/1500], Loss: 1.6131\n",
      "Epoch [2/10], Step [700/1500], Loss: 1.6003\n",
      "Epoch [2/10], Step [800/1500], Loss: 1.6164\n",
      "Epoch [2/10], Step [900/1500], Loss: 1.6134\n",
      "Epoch [2/10], Step [1000/1500], Loss: 1.5918\n",
      "Epoch [2/10], Step [1100/1500], Loss: 1.5721\n",
      "Epoch [2/10], Step [1200/1500], Loss: 1.5935\n",
      "Epoch [2/10], Step [1300/1500], Loss: 1.5993\n",
      "Epoch [2/10], Step [1400/1500], Loss: 1.5747\n",
      "Epoch [2/10], Step [1500/1500], Loss: 1.5354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 2/10 [00:59<04:05, 30.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [100/1500], Loss: 1.5488\n",
      "Epoch [3/10], Step [200/1500], Loss: 1.5214\n",
      "Epoch [3/10], Step [300/1500], Loss: 1.5384\n",
      "Epoch [3/10], Step [400/1500], Loss: 1.5159\n",
      "Epoch [3/10], Step [500/1500], Loss: 1.5528\n",
      "Epoch [3/10], Step [600/1500], Loss: 1.5481\n",
      "Epoch [3/10], Step [700/1500], Loss: 1.5597\n",
      "Epoch [3/10], Step [800/1500], Loss: 1.5139\n",
      "Epoch [3/10], Step [900/1500], Loss: 1.5637\n",
      "Epoch [3/10], Step [1000/1500], Loss: 1.5458\n",
      "Epoch [3/10], Step [1100/1500], Loss: 1.5326\n",
      "Epoch [3/10], Step [1200/1500], Loss: 1.5427\n",
      "Epoch [3/10], Step [1300/1500], Loss: 1.5113\n",
      "Epoch [3/10], Step [1400/1500], Loss: 1.5328\n",
      "Epoch [3/10], Step [1500/1500], Loss: 1.4963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 3/10 [01:23<03:20, 28.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [100/1500], Loss: 1.4834\n",
      "Epoch [4/10], Step [200/1500], Loss: 1.4825\n",
      "Epoch [4/10], Step [300/1500], Loss: 1.4775\n",
      "Epoch [4/10], Step [400/1500], Loss: 1.4980\n",
      "Epoch [4/10], Step [500/1500], Loss: 1.4763\n",
      "Epoch [4/10], Step [600/1500], Loss: 1.5077\n",
      "Epoch [4/10], Step [700/1500], Loss: 1.5075\n",
      "Epoch [4/10], Step [800/1500], Loss: 1.5036\n",
      "Epoch [4/10], Step [900/1500], Loss: 1.4988\n",
      "Epoch [4/10], Step [1000/1500], Loss: 1.4839\n",
      "Epoch [4/10], Step [1100/1500], Loss: 1.4658\n",
      "Epoch [4/10], Step [1200/1500], Loss: 1.4943\n",
      "Epoch [4/10], Step [1300/1500], Loss: 1.4768\n",
      "Epoch [4/10], Step [1400/1500], Loss: 1.4789\n",
      "Epoch [4/10], Step [1500/1500], Loss: 1.4618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [01:49<02:46, 27.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [100/1500], Loss: 1.4365\n",
      "Epoch [5/10], Step [200/1500], Loss: 1.4280\n",
      "Epoch [5/10], Step [300/1500], Loss: 1.4459\n",
      "Epoch [5/10], Step [400/1500], Loss: 1.4538\n",
      "Epoch [5/10], Step [500/1500], Loss: 1.4284\n",
      "Epoch [5/10], Step [600/1500], Loss: 1.4252\n",
      "Epoch [5/10], Step [700/1500], Loss: 1.4324\n",
      "Epoch [5/10], Step [800/1500], Loss: 1.4346\n",
      "Epoch [5/10], Step [900/1500], Loss: 1.4595\n",
      "Epoch [5/10], Step [1000/1500], Loss: 1.4569\n",
      "Epoch [5/10], Step [1100/1500], Loss: 1.4525\n",
      "Epoch [5/10], Step [1200/1500], Loss: 1.4394\n",
      "Epoch [5/10], Step [1300/1500], Loss: 1.4180\n",
      "Epoch [5/10], Step [1400/1500], Loss: 1.4459\n",
      "Epoch [5/10], Step [1500/1500], Loss: 1.4533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [02:14<02:15, 27.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [100/1500], Loss: 1.4339\n",
      "Epoch [6/10], Step [200/1500], Loss: 1.4237\n",
      "Epoch [6/10], Step [300/1500], Loss: 1.4331\n",
      "Epoch [6/10], Step [400/1500], Loss: 1.3928\n",
      "Epoch [6/10], Step [500/1500], Loss: 1.3936\n",
      "Epoch [6/10], Step [600/1500], Loss: 1.4018\n",
      "Epoch [6/10], Step [700/1500], Loss: 1.3809\n",
      "Epoch [6/10], Step [800/1500], Loss: 1.3692\n",
      "Epoch [6/10], Step [900/1500], Loss: 1.4430\n",
      "Epoch [6/10], Step [1000/1500], Loss: 1.4558\n",
      "Epoch [6/10], Step [1100/1500], Loss: 1.4233\n",
      "Epoch [6/10], Step [1200/1500], Loss: 1.4311\n",
      "Epoch [6/10], Step [1300/1500], Loss: 1.3925\n",
      "Epoch [6/10], Step [1400/1500], Loss: 1.4472\n",
      "Epoch [6/10], Step [1500/1500], Loss: 1.4331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [02:39<01:44, 26.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [100/1500], Loss: 1.3769\n",
      "Epoch [7/10], Step [200/1500], Loss: 1.3911\n",
      "Epoch [7/10], Step [300/1500], Loss: 1.3981\n",
      "Epoch [7/10], Step [400/1500], Loss: 1.3930\n",
      "Epoch [7/10], Step [500/1500], Loss: 1.4157\n",
      "Epoch [7/10], Step [600/1500], Loss: 1.3996\n",
      "Epoch [7/10], Step [700/1500], Loss: 1.3669\n",
      "Epoch [7/10], Step [800/1500], Loss: 1.4014\n",
      "Epoch [7/10], Step [900/1500], Loss: 1.3958\n",
      "Epoch [7/10], Step [1000/1500], Loss: 1.3640\n",
      "Epoch [7/10], Step [1100/1500], Loss: 1.4074\n",
      "Epoch [7/10], Step [1200/1500], Loss: 1.4242\n",
      "Epoch [7/10], Step [1300/1500], Loss: 1.3776\n",
      "Epoch [7/10], Step [1400/1500], Loss: 1.3872\n",
      "Epoch [7/10], Step [1500/1500], Loss: 1.3849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [03:03<01:17, 25.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [100/1500], Loss: 1.3767\n",
      "Epoch [8/10], Step [200/1500], Loss: 1.3727\n",
      "Epoch [8/10], Step [300/1500], Loss: 1.3681\n",
      "Epoch [8/10], Step [400/1500], Loss: 1.3230\n",
      "Epoch [8/10], Step [500/1500], Loss: 1.3726\n",
      "Epoch [8/10], Step [600/1500], Loss: 1.3734\n",
      "Epoch [8/10], Step [700/1500], Loss: 1.3568\n",
      "Epoch [8/10], Step [800/1500], Loss: 1.3669\n",
      "Epoch [8/10], Step [900/1500], Loss: 1.3966\n",
      "Epoch [8/10], Step [1000/1500], Loss: 1.3712\n",
      "Epoch [8/10], Step [1100/1500], Loss: 1.3594\n",
      "Epoch [8/10], Step [1200/1500], Loss: 1.3890\n",
      "Epoch [8/10], Step [1300/1500], Loss: 1.3904\n",
      "Epoch [8/10], Step [1400/1500], Loss: 1.3368\n",
      "Epoch [8/10], Step [1500/1500], Loss: 1.3659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [03:30<00:51, 25.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [100/1500], Loss: 1.3468\n",
      "Epoch [9/10], Step [200/1500], Loss: 1.3310\n",
      "Epoch [9/10], Step [300/1500], Loss: 1.3175\n",
      "Epoch [9/10], Step [400/1500], Loss: 1.3459\n",
      "Epoch [9/10], Step [500/1500], Loss: 1.3525\n",
      "Epoch [9/10], Step [600/1500], Loss: 1.3491\n",
      "Epoch [9/10], Step [700/1500], Loss: 1.3470\n",
      "Epoch [9/10], Step [800/1500], Loss: 1.3364\n",
      "Epoch [9/10], Step [900/1500], Loss: 1.3448\n",
      "Epoch [9/10], Step [1000/1500], Loss: 1.3625\n",
      "Epoch [9/10], Step [1100/1500], Loss: 1.3670\n",
      "Epoch [9/10], Step [1200/1500], Loss: 1.3594\n",
      "Epoch [9/10], Step [1300/1500], Loss: 1.3682\n",
      "Epoch [9/10], Step [1400/1500], Loss: 1.3815\n",
      "Epoch [9/10], Step [1500/1500], Loss: 1.3461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [03:54<00:25, 25.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [100/1500], Loss: 1.3381\n",
      "Epoch [10/10], Step [200/1500], Loss: 1.3037\n",
      "Epoch [10/10], Step [300/1500], Loss: 1.3564\n",
      "Epoch [10/10], Step [400/1500], Loss: 1.3557\n",
      "Epoch [10/10], Step [500/1500], Loss: 1.3224\n",
      "Epoch [10/10], Step [600/1500], Loss: 1.3286\n",
      "Epoch [10/10], Step [700/1500], Loss: 1.3540\n",
      "Epoch [10/10], Step [800/1500], Loss: 1.3116\n",
      "Epoch [10/10], Step [900/1500], Loss: 1.3565\n",
      "Epoch [10/10], Step [1000/1500], Loss: 1.3257\n",
      "Epoch [10/10], Step [1100/1500], Loss: 1.3482\n",
      "Epoch [10/10], Step [1200/1500], Loss: 1.3456\n",
      "Epoch [10/10], Step [1300/1500], Loss: 1.3313\n",
      "Epoch [10/10], Step [1400/1500], Loss: 1.3229\n",
      "Epoch [10/10], Step [1500/1500], Loss: 1.3354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [04:18<00:00, 24.94s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "time_start = time.time()\n",
    "\n",
    "model.init_weight()\n",
    "\n",
    "for epoch in tqdm(range(src['num_epochs'])):\n",
    "    current_loss = 0.0\n",
    "#     model.train(True)\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        step = i + 1\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        if step % 100 == 0 and step != 0:     # print every 100 mini-batches\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' %\n",
    "                  (epoch + 1, src['num_epochs'], step, len(trainloader)//100 * 100, current_loss / 100))\n",
    "            current_loss = 0.0 #100동안 있었던 loss의 누적값 평균, 그 후 reset\n",
    "            \n",
    "traintime = time.time() - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 2500 test images: 48 %\n",
      "Time elapsed: 258.19803500175476 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for i, data in enumerate(testloader):\n",
    "    inputs, labels = data\n",
    "#     images = images.view(-1, 28*28)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.shape[0]\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 2500 test images: %d %%' % (100 * correct / total))\n",
    "print( 'Time elapsed: {} seconds'.format(traintime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "##### batch size : 32 , epoch size : 10 \n",
    "\n",
    "#### 기본 모델\n",
    "Epoch [10/10], Step [1500/1500], Loss: 1.9926\n",
    "\n",
    "Accuracy of the network on the 2500 test images: 26 %\n",
    "\n",
    "Time elapsed: 205.56801676750183 seconds\n",
    "\n",
    "#### 기본 모델 + adam\n",
    "Epoch [10/10], Step [1500/1500], Loss: 1.3857\n",
    "\n",
    "Accuracy of the network on the 2500 test images: 46 %\n",
    "\n",
    "Time elapsed: 235.60971903800964 seconds\n",
    "\n",
    "#### dropout 모델 + adam\n",
    "Epoch [10/10], Step [1500/1500], Loss: 1.9687\n",
    "\n",
    "Accuracy of the network on the 2500 test images: 28 %\n",
    "\n",
    "Time elapsed: 230.63831567764282 seconds\n",
    "\n",
    "#### batch normalization 모델 + adam\n",
    "Epoch [10/10], Step [1500/1500], Loss: 1.3354\n",
    "\n",
    "Accuracy of the network on the 2500 test images: 48 %\n",
    "\n",
    "Time elapsed: 258.19803500175476 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basic + adam 모델의 경우  최적화를 하지 않은 basic 모델에 비해 accuracy가 약 20% 올랐고 loss도 많이 줄었다.\n",
    "\n",
    "학습에 걸린 시간은 15%정도 증가하였다.  최적화 과정에서 시간이 소요된 것으로 보인다.\n",
    "\n",
    "-\n",
    "\n",
    "dropout + adam 모델의 경우 basic + adam 모델과 비교해 보았을 때 시간은 거의 차이가 나지 않은 반면 loss 과 accuracy가 매우 나빠졌다.\n",
    "\n",
    "이것은 노드를 확률적으로 끄는 dropout의 특성상 특정 w에 의존하지 않아 overfitting을 낮추는 장점이 있지만 상대적으로 w의 학습이 느려져 더 많은 epoch가 필요한 것으로 보인다.\n",
    "\n",
    "-\n",
    "\n",
    "batch normalization + adam 모델의 경우 basic + adam 모델과 비교해 보았을 때 loss가 좀더 줄었고 accuracy가 2% 더 높아져 가장 높은 accuracy를 보였다. 그에 비해 학습시간은 20초 가량 더 걸렸다. batchNorm을 통해 epoch 대비 학습속도가 상승한 것으로 보인다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
